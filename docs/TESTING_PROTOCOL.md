# Testing Protocol - Coding AI Platform v2

**Mandatory testing protocol for all packs from Pack 3 onwards.**

---

## üìã **Overview**

Every pack must pass **THREE levels of testing**:
1. ‚úÖ **Unit Tests** (mocked dependencies)
2. ‚úÖ **Integration Tests** (real components, mocked AI)
3. ‚úÖ **Real-World Tests** (real AI, real execution)

**A pack is NOT complete until all three levels pass.**

---

## üîÑ **Testing Workflow**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 1: PRE-BUILD VALIDATION                          ‚îÇ
‚îÇ  - Review requirements                                  ‚îÇ
‚îÇ  - Check dependencies exist                             ‚îÇ
‚îÇ  - Verify interfaces are defined                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 2: BUILD                                         ‚îÇ
‚îÇ  - Write code                                           ‚îÇ
‚îÇ  - Write unit tests                                     ‚îÇ
‚îÇ  - Write integration tests                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 3: POST-BUILD UNIT TESTING                       ‚îÇ
‚îÇ  - Run: npm test                                        ‚îÇ
‚îÇ  - All tests must pass                                  ‚îÇ
‚îÇ  - Code coverage > 80%                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 4: REAL-WORLD INTEGRATION TESTING                ‚îÇ
‚îÇ  - Run diagnostic tests                                 ‚îÇ
‚îÇ  - Run interactive testing (MANDATORY)                  ‚îÇ
‚îÇ  - Run automated real-world tests                       ‚îÇ
‚îÇ  - Run stress tests                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 5: BUG FIXES & ITERATION                         ‚îÇ
‚îÇ  - Fix any issues found                                 ‚îÇ
‚îÇ  - Re-run all tests                                     ‚îÇ
‚îÇ  - Document known limitations                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚úÖ PACK COMPLETE                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìù **Phase 1: Pre-Build Validation**

**Before writing any code, verify:**

### **Checklist:**
- [ ] Requirements are clear and documented
- [ ] All dependencies are available
- [ ] Interfaces/types are defined
- [ ] Previous packs are complete and tested
- [ ] Test strategy is defined

### **Questions to Answer:**
1. What are we building?
2. What are the inputs and outputs?
3. What dependencies does it have?
4. How will we test it?
5. What could go wrong?

---

## üß™ **Phase 2: Build**

**While building, create tests alongside code:**

### **For Each Component:**
1. Write the interface/type first
2. Write unit tests (with mocks)
3. Write the implementation
4. Write integration tests (real components)
5. Verify tests pass

### **Test Coverage Requirements:**
- **Unit tests**: Every public method
- **Integration tests**: Every major workflow
- **Edge cases**: Error handling, invalid inputs, boundary conditions

---

## ‚úÖ **Phase 3: Post-Build Unit Testing**

**After code is complete, run full test suite:**

### **Command:**
```bash
npm test
```

### **Success Criteria:**
- ‚úÖ All tests pass (100%)
- ‚úÖ No TypeScript errors
- ‚úÖ No linting errors
- ‚úÖ Code coverage > 80%

### **If Tests Fail:**
1. Fix the code
2. Re-run tests
3. Repeat until all pass

**DO NOT proceed to Phase 4 until all unit tests pass.**

---

## üåç **Phase 4: Real-World Integration Testing**

**Test with real AI models and real execution:**

### **Step 1: Diagnostic Tests**
```bash
npm run diagnose:ollama
```

**Success Criteria:**
- ‚úÖ Ollama is available
- ‚úÖ Model returns valid responses
- ‚úÖ JSON parsing works

### **Step 2: Interactive Testing (MANDATORY)**
```bash
npm run interactive:agent
```

**Required Test Cases:**
1. **Simple Tasks** - Verify basic functionality
   - Example: "Create a file called test.txt with Hello World"
   - Expected: File created with correct content

2. **Complex Tasks** - Verify multi-step workflows
   - Example: "Create 3 files with different content"
   - Expected: All files created correctly

3. **Edge Cases** - Try to break the system
   - Invalid paths: `../../etc/passwd`
   - Non-existent files: "Read file that doesn't exist"
   - Malformed requests: Empty input, gibberish
   - Boundary conditions: Very long content, special characters

4. **Error Handling** - Verify graceful failures
   - Request impossible tasks
   - Provide invalid parameters
   - Test retry logic

**Success Criteria:**
- ‚úÖ Simple tasks complete successfully
- ‚úÖ Complex tasks decompose and execute correctly
- ‚úÖ Edge cases handled gracefully (no crashes)
- ‚úÖ Error messages are clear and helpful
- ‚úÖ System recovers from failures
- ‚úÖ Performance is acceptable (< 30s per task)

**Documentation Required:**
- Document any tasks that break the system
- Note any unexpected behaviors
- Record performance observations
- Add findings to TEST_RESULTS.md

### **Step 3: Automated Real-World Tests**
```bash
npm run test:real-agent
```

**Success Criteria:**
- ‚úÖ All predefined test cases pass
- ‚úÖ Output validation succeeds
- ‚úÖ No unexpected errors

### **Step 4: Stress Tests**
```bash
npm run stress:agent
```

**Success Criteria:**
- ‚úÖ Handles ambiguous tasks gracefully
- ‚úÖ Handles complex multi-step tasks
- ‚úÖ Security checks work (path validation)
- ‚úÖ Error recovery works

---

## üêõ **Phase 5: Bug Fixes & Iteration**

**If any real-world tests fail:**

### **Process:**
1. **Document the issue**
   - What failed?
   - What was expected?
   - What actually happened?
   - How to reproduce?

2. **Categorize the issue**
   - üî¥ **Critical**: System doesn't work at all
   - üü° **Major**: Feature broken, workaround exists
   - üü¢ **Minor**: Edge case, cosmetic issue

3. **Fix the issue**
   - Write a failing test first
   - Fix the code
   - Verify test passes
   - Re-run all tests

4. **Re-test**
   - Run unit tests: `npm test`
   - Run real-world tests again
   - Verify fix works

5. **Document**
   - Update TROUBLESHOOTING.md
   - Add to known limitations if needed

---

## üìä **Test Results Documentation**

**After each pack, document results:**

### **Template:**
```markdown
## Pack X.Y - [Name]

### Unit Tests
- Total: X tests
- Passed: X
- Failed: 0
- Coverage: X%

### Integration Tests
- Total: X tests
- Passed: X
- Failed: 0

### Real-World Tests
- Diagnostic: ‚úÖ PASS
- Interactive Testing: ‚úÖ PASS (4 categories tested: simple, complex, edge cases, error handling)
- Automated Tests: ‚úÖ PASS (X/X cases)
- Stress Tests: ‚úÖ PASS (X/X cases)

### Known Issues
- None

### Performance
- Average task time: Xms
- Max task time: Xms

### Status
‚úÖ COMPLETE - All tests passing
```

---

## üéØ **Success Criteria Summary**

**A pack is complete when:**
- ‚úÖ All unit tests pass (npm test)
- ‚úÖ All integration tests pass
- ‚úÖ Diagnostic tests pass
- ‚úÖ Interactive testing complete (all 4 categories: simple, complex, edge cases, error handling)
- ‚úÖ Automated real-world tests pass
- ‚úÖ Stress tests pass
- ‚úÖ All bugs are fixed or documented
- ‚úÖ Test results are documented

**If ANY of these fail, the pack is NOT complete.**

---

## üö´ **Common Mistakes to Avoid**

1. ‚ùå Skipping real-world tests ("unit tests are enough")
2. ‚ùå Not testing with real AI models
3. ‚ùå Not testing error cases
4. ‚ùå Not documenting test results
5. ‚ùå Moving to next pack with failing tests
6. ‚ùå Only testing happy path
7. ‚ùå Not testing performance

---

## üìö **Test Scripts Reference**

| Script | Purpose | When to Use |
|--------|---------|-------------|
| `npm test` | Unit + integration tests | After every code change |
| `npm run diagnose:ollama` | Check Ollama health | Before real-world tests |
| `npm run interactive:agent` | Interactive testing (MANDATORY) | Phase 4 - Manual testing, try to break it |
| `npm run test:real-agent` | Automated real-world tests | Phase 4 - Before marking pack complete |
| `npm run stress:agent` | Edge cases + stress tests | Phase 4 - Final validation |

---

**This protocol is MANDATORY for all future packs.**

